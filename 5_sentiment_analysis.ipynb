{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPYwHvD9k5c/FtKoB92T7+i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OdysseusPolymetis/colabs_for_nlp/blob/main/5_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza"
      ],
      "metadata": {
        "id": "jLk-ljiqZwrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import stanza\n",
        "from lxml import etree as ET\n",
        "import lxml.html\n",
        "import string\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "ZVAhMECQbq9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o8xlWr2FQYL"
      },
      "outputs": [],
      "source": [
        "# Utilisation de CUDA\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialisation du pipeline avec le modèle en utilisant CUDA\n",
        "sentiment_pipe = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"ac0hik/Sentiment_Analysis_French\",\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ebalzac/FC/refs/heads/gh-pages/balzac-22-FC-pere-goriot.xml"
      ],
      "metadata": {
        "id": "aZq3ivLvGdmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def strip_ns_prefix(tree):\n",
        "    query = \"descendant-or-self::*[namespace-uri()!='']\"\n",
        "    for element in tree.xpath(query):\n",
        "        element.tag = ET.QName(element).localname\n",
        "    return tree"
      ],
      "metadata": {
        "id": "ptPjsVNBbyUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath_of_text = \"/content/balzac-22-FC-pere-goriot.xml\""
      ],
      "metadata": {
        "id": "diQ-3iFOcKoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_stanza = stanza.Pipeline(lang='fr', processors='tokenize,mwt')"
      ],
      "metadata": {
        "id": "4bpMy-YKddv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = ET.XMLParser(remove_blank_text=True, resolve_entities=False, encoding='utf8')\n",
        "tree = strip_ns_prefix(ET.parse(filepath_of_text, parser))\n",
        "ps = tree.xpath(\".//p\")\n",
        "paragraphs= []\n",
        "for p in ps:\n",
        "  sentences = []\n",
        "  for sentence in nlp_stanza(\"\".join(p.itertext())).sentences:\n",
        "    sentences.append(sentence.text)\n",
        "  paragraphs.append(sentences)"
      ],
      "metadata": {
        "id": "pVQkc6HgbdXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(paragraphs)"
      ],
      "metadata": {
        "id": "Sc5suAv7hu-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph_sentiments = []\n",
        "for paragraph in paragraphs:\n",
        "    sentence_scores = []\n",
        "    confidence_scores = []  # Liste pour stocker les scores de confiance\n",
        "\n",
        "    for sentence in paragraph:\n",
        "        sentiment = sentiment_pipe(sentence)[0]\n",
        "        confidence = sentiment['score']\n",
        "        confidence_scores.append(confidence)\n",
        "\n",
        "        # Calcul du score de base en fonction de l'étiquette\n",
        "        if sentiment['label'] == 'negative':\n",
        "            score = - (confidence - 0.5) * 2  # Score négatif ajusté\n",
        "        elif sentiment['label'] == 'positive':\n",
        "            score = (confidence - 0.5) * 2  # Score positif ajusté\n",
        "        else:  # 'neutral'\n",
        "            score = 0  # Pas de sentiment\n",
        "\n",
        "        sentence_scores.append(score)\n",
        "\n",
        "    # Calcul de la moyenne des scores de sentiment pour le paragraphe\n",
        "    avg_score = np.mean(sentence_scores)\n",
        "\n",
        "    # Calcul de la moyenne des scores de confiance\n",
        "    avg_confidence = np.mean(confidence_scores)\n",
        "\n",
        "    # Ajustement du score basé sur la longueur du paragraphe\n",
        "    paragraph_length = len(paragraph)  # Nombre de phrases dans le paragraphe\n",
        "\n",
        "    # Ajuster l'impact de la longueur et de la confiance de manière plus prononcée\n",
        "    if paragraph_length > 4:  # Paragraphe long\n",
        "        adjusted_score = avg_score * (1 + 0.2 * (avg_confidence - 0.5))  # Amplification plus forte\n",
        "    elif paragraph_length <= 2:  # Paragraphe court\n",
        "        adjusted_score = avg_score * (1 - 0.2 * (1 - avg_confidence))  # Réduction plus forte\n",
        "    else:\n",
        "        adjusted_score = avg_score  # Pas de changement pour les paragraphes de taille moyenne\n",
        "\n",
        "    paragraph_sentiments.append(adjusted_score)"
      ],
      "metadata": {
        "id": "nNlG6SinhqSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices_to_print = [30, 240, 930]\n",
        "for index in indices_to_print:\n",
        "    if index < len(paragraphs):\n",
        "        paragraph = paragraphs[index]\n",
        "\n",
        "        full_paragraph = \" \".join(paragraph)\n",
        "\n",
        "        print(f\"\\nParagraphe {index}:\")\n",
        "        print(full_paragraph)\n",
        "        print(f\"Score moyen de sentiment: {paragraph_sentiments[index]}\")"
      ],
      "metadata": {
        "id": "sbk8ZlDCdM4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 50\n",
        "smoothed_sentiments = np.convolve(paragraph_sentiments, np.ones(window_size), 'valid') / window_size\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.scatter(range(len(paragraph_sentiments)), paragraph_sentiments, alpha=0.3, color='lightgray', label='Paragraph Sentiment Scores')\n",
        "\n",
        "plt.plot(range(window_size - 1, len(paragraph_sentiments)), smoothed_sentiments, color='blue', label='Smoothed Sentiment Trend')\n",
        "\n",
        "plt.ylim(-1, 1)\n",
        "\n",
        "plt.xlabel('Paragraph Number')\n",
        "plt.ylabel('Average Sentiment Score')\n",
        "plt.title('Evolution of Average Sentiment per Paragraph')\n",
        "plt.legend()\n",
        "\n",
        "for i, sentiment in enumerate(paragraph_sentiments):\n",
        "    if i % 10 == 0:\n",
        "        plt.annotate(str(i), (i, sentiment), textcoords=\"offset points\", xytext=(0, 5), ha='center')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vbIKG6AUkOU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_paragraphs(indices):\n",
        "  for i in indices:\n",
        "    if 0 <= i < len(paragraphs):\n",
        "      print(f\"Paragraph {i}:\")\n",
        "      for sentence in paragraphs[i]:\n",
        "        print(sentence)\n",
        "    else:\n",
        "      print(f\"Index {i} is out of bounds.\")\n",
        "\n",
        "display_paragraphs([570])"
      ],
      "metadata": {
        "id": "w_qlyc_l1MZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_paragraphs([1370])"
      ],
      "metadata": {
        "id": "FdEuNsH32pwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_paragraphs([320])"
      ],
      "metadata": {
        "id": "pyRy2omTZLeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_paragraphs([230])"
      ],
      "metadata": {
        "id": "3TmDEygMZSlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_paragraphs([840])"
      ],
      "metadata": {
        "id": "ce1dcDfZZjku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_paragraphs([1250])"
      ],
      "metadata": {
        "id": "iaEMhomRj6YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_paragraphs([1260])"
      ],
      "metadata": {
        "id": "omJANmzrkbnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_paragraphs([1557])"
      ],
      "metadata": {
        "id": "DyyTSu69kAPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avec vos propres txt maintenant"
      ],
      "metadata": {
        "id": "aVnj256SomcG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention, je n'ai pas encore testé ce code pour tout type de texte, il est possible qu'il y ait des erreurs."
      ],
      "metadata": {
        "id": "3Nykp2rPpjqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "tXDIVrcEoqOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Veuillez téléverser un fichier .txt contenant votre texte :\")\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "rKg8BGBhotiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = list(uploaded.keys())[0]\n",
        "    print(f\"Fichier chargé : {filename}\")"
      ],
      "metadata": {
        "id": "QcD_bbo7ouo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "        user_text = f.read()"
      ],
      "metadata": {
        "id": "ZJ2kAisto2Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_paragraphs = [p.strip() for p in user_text.split(\"\\n\\n\") if p.strip()]"
      ],
      "metadata": {
        "id": "Udx-TZqlo6dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs_user = []\n",
        "    for p in raw_paragraphs:\n",
        "        doc = nlp_stanza(p)\n",
        "        sentences = [sent.text for sent in doc.sentences]\n",
        "        if sentences:\n",
        "            paragraphs_user.append(sentences)"
      ],
      "metadata": {
        "id": "DDuofCjspCGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(paragraphs_user) == 0:\n",
        "        print(\"Impossible d'extraire des phrases du texte, vérifiez le format.\")\n",
        "    else:\n",
        "        print(f\"Nombre de paragraphes détectés : {len(paragraphs_user)}\")\n",
        "\n",
        "        paragraph_sentiments_user = []\n",
        "\n",
        "        for paragraph in paragraphs_user:\n",
        "            sentence_scores = []\n",
        "            confidence_scores = []\n",
        "\n",
        "            for sentence in paragraph:\n",
        "                result = sentiment_pipe(sentence)[0]\n",
        "                confidence = result[\"score\"]\n",
        "                confidence_scores.append(confidence)\n",
        "\n",
        "                if result[\"label\"] == \"negative\":\n",
        "                    score = -(confidence - 0.5) * 2\n",
        "                elif result[\"label\"] == \"positive\":\n",
        "                    score = (confidence - 0.5) * 2\n",
        "                else:\n",
        "                    score = 0\n",
        "\n",
        "                sentence_scores.append(score)\n",
        "\n",
        "            avg_score = np.mean(sentence_scores)\n",
        "            avg_confidence = np.mean(confidence_scores)\n",
        "            paragraph_length = len(paragraph)\n",
        "\n",
        "            if paragraph_length > 4:\n",
        "                adjusted_score = avg_score * (1 + 0.2 * (avg_confidence - 0.5))\n",
        "            elif paragraph_length <= 2:\n",
        "                adjusted_score = avg_score * (1 - 0.2 * (1 - avg_confidence))\n",
        "            else:\n",
        "                adjusted_score = avg_score\n",
        "\n",
        "            paragraph_sentiments_user.append(adjusted_score)\n",
        "\n",
        "        if len(paragraph_sentiments_user) < 3:\n",
        "            window_size = len(paragraph_sentiments_user)\n",
        "        else:\n",
        "            window_size = max(3, min(20, len(paragraph_sentiments_user) // 4))\n",
        "\n",
        "        if window_size > 1 and len(paragraph_sentiments_user) >= window_size:\n",
        "            smoothed_sentiments_user = np.convolve(\n",
        "                paragraph_sentiments_user,\n",
        "                np.ones(window_size),\n",
        "                \"valid\"\n",
        "            ) / window_size\n",
        "        else:\n",
        "            smoothed_sentiments_user = None\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        plt.scatter(\n",
        "            range(len(paragraph_sentiments_user)),\n",
        "            paragraph_sentiments_user,\n",
        "            alpha=0.3,\n",
        "            label=\"Scores des paragraphes\"\n",
        "        )\n",
        "\n",
        "        if smoothed_sentiments_user is not None:\n",
        "            plt.plot(\n",
        "                range(window_size - 1, len(paragraph_sentiments_user)),\n",
        "                smoothed_sentiments_user,\n",
        "                label=\"Tendance lissée\"\n",
        "            )\n",
        "\n",
        "        plt.ylim(-1, 1)\n",
        "        plt.xlabel(\"Numéro de paragraphe\")\n",
        "        plt.ylabel(\"Score moyen de sentiment\")\n",
        "        plt.title(f\"Évolution du sentiment pour le texte : {filename}\")\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "Ijh-tGLPpDXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_user_paragraphs(indices):\n",
        "            for i in indices:\n",
        "                if 0 <= i < len(paragraphs_user):\n",
        "                    print(f\"=== Paragraphe {i} (score {paragraph_sentiments_user[i]:.3f}) ===\")\n",
        "                    for sent in paragraphs_user[i]:\n",
        "                        print(sent)\n",
        "                    print()\n",
        "                else:\n",
        "                    print(f\"Indice {i} hors limites (0 – {len(paragraphs_user)-1}).\")\n",
        "\n",
        "        print(\"\\nVous pouvez maintenant appeler par exemple :\")\n",
        "        print(\"  display_user_paragraphs([0, 1, 2])\")"
      ],
      "metadata": {
        "id": "9p3Z9zYupWA7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}