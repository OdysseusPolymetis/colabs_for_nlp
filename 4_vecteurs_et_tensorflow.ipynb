{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuDgti7pG/5ZdlGDytO7ap",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OdysseusPolymetis/colabs_for_nlp/blob/main/4_vecteurs_et_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuIQiBPlDYvT"
      },
      "outputs": [],
      "source": [
        "!pip install gensim matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.manifold import TSNE"
      ],
      "metadata": {
        "id": "E8scNnXmDjh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Chargement d'un modèle d'embedding pré-entraîné (version légère)\n",
        "# Téléchargement d'un modèle Word2Vec pré-entraîné en français\n",
        "!wget -O frwiki.gensim https://zenodo.org/records/6004718/files/roman20_mdt=skgr-opt=negsam-itr=10-dim=300-win=6-min=50.gensim?download=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgHDEMI_DmVP",
        "outputId": "9957bc03-63f0-4fbe-a229-37d043f6176f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-03 09:33:40--  https://zenodo.org/records/6004718/files/roman20_mdt=skgr-opt=negsam-itr=10-dim=300-win=6-min=50.gensim?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.43.25, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 107458244 (102M) [application/octet-stream]\n",
            "Saving to: ‘frwiki.gensim’\n",
            "\n",
            "frwiki.gensim       100%[===================>] 102.48M  3.83MB/s    in 1m 59s  \n",
            "\n",
            "2025-04-03 09:35:40 (883 KB/s) - ‘frwiki.gensim’ saved [107458244/107458244]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = KeyedVectors.load('frwiki.gensim')"
      ],
      "metadata": {
        "id": "2yhdG2WwD4ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "literary_terms = [\"roman_nom\", \"poésie_nom\", \"auteur_nom\", \"personnage_nom\", \"métaphore_nom\"]\n",
        "for term in literary_terms:\n",
        "    try:\n",
        "        similar_words = model.wv.most_similar(term, topn=5)\n",
        "        print(f\"\\nMots similaires à '{term}':\")\n",
        "        for word, similarity in similar_words:\n",
        "            print(f\"  {word}: {similarity:.4f}\")\n",
        "    except KeyError:\n",
        "        print(f\"Le mot '{term}' n'est pas dans le vocabulaire.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQgwYkYeEmKR",
        "outputId": "2e80178d-0b3f-4f60-e165-395e05e41e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mots similaires à 'roman_nom':\n",
            "  bouquin_nom: 0.5913\n",
            "  livre_nom: 0.5840\n",
            "  feuilleton_nom: 0.5622\n",
            "  polar_nom: 0.5528\n",
            "  publier_ver: 0.5345\n",
            "\n",
            "Mots similaires à 'poésie_nom':\n",
            "  littérature_nom: 0.5188\n",
            "  poème_nom: 0.5042\n",
            "  poète_nom: 0.4918\n",
            "  sonnet_nom: 0.4831\n",
            "  poétique_adj: 0.4714\n",
            "\n",
            "Mots similaires à 'auteur_nom':\n",
            "  illustrateur_nom: 0.5687\n",
            "  éditeur_nom: 0.5411\n",
            "  roman_nom: 0.5259\n",
            "  écrivain_nom: 0.5219\n",
            "  texte_nom: 0.5211\n",
            "\n",
            "Mots similaires à 'personnage_nom':\n",
            "  individu_nom: 0.5343\n",
            "  personnalité_nom: 0.5234\n",
            "  acteur_nom: 0.4890\n",
            "  inconnu_nom: 0.4744\n",
            "  héros_nom: 0.4471\n",
            "\n",
            "Mots similaires à 'métaphore_nom':\n",
            "  formulation_nom: 0.4190\n",
            "  heidegger_nam: 0.3999\n",
            "  langage_nom: 0.3967\n",
            "  locution_nom: 0.3967\n",
            "  rhétorique_nom: 0.3932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "historical_terms = [\"révolution_nom\", \"guerre_nom\", \"tuer_ver\", \"république_nom\", \"siècle_nom\"]\n",
        "for term in historical_terms:\n",
        "    try:\n",
        "        similar_words = model.wv.most_similar(term, topn=5)\n",
        "        print(f\"\\nMots similaires à '{term}':\")\n",
        "        for word, similarity in similar_words:\n",
        "            print(f\"  {word}: {similarity:.4f}\")\n",
        "    except KeyError:\n",
        "        print(f\"Le mot '{term}' n'est pas dans le vocabulaire.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxqhUiYoHxE0",
        "outputId": "d250a5fb-94f9-43c5-f741-8b7dea98cb10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mots similaires à 'révolution_nom':\n",
            "  guerre_nom: 0.5249\n",
            "  révolutionnaire_nom: 0.5184\n",
            "  révolutionnaire_adj: 0.5045\n",
            "  insurrection_nom: 0.5005\n",
            "  prolétariat_nom: 0.4660\n",
            "\n",
            "Mots similaires à 'guerre_nom':\n",
            "  bataille_nom: 0.5717\n",
            "  révolution_nom: 0.5249\n",
            "  combat_nom: 0.5125\n",
            "  conflit_nom: 0.5002\n",
            "  guerre_nam: 0.4633\n",
            "\n",
            "Mots similaires à 'tuer_ver':\n",
            "  assassiner_ver: 0.7172\n",
            "  mourir_ver: 0.6211\n",
            "  égorger_ver: 0.6039\n",
            "  massacrer_ver: 0.5989\n",
            "  suicider_ver: 0.5836\n",
            "\n",
            "Mots similaires à 'république_nom':\n",
            "  gouvernement_nom: 0.5829\n",
            "  président_nom: 0.5585\n",
            "  ministre_nom: 0.4974\n",
            "  poincaré_nam: 0.4891\n",
            "  procureur_nom: 0.4826\n",
            "\n",
            "Mots similaires à 'siècle_nom':\n",
            "  xixe_num: 0.6206\n",
            "  millénaire_nom: 0.5647\n",
            "  xxe_num: 0.5394\n",
            "  xviie_num: 0.5328\n",
            "  année_nom: 0.5322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    result = model.wv.most_similar(positive=['roi_nom', 'femme_nom'], negative=['homme_nom'], topn=1)\n",
        "    print(f\"roi - homme + femme = {result[0][0]}\")\n",
        "except KeyError:\n",
        "    print(\"Un des mots n'est pas dans le vocabulaire.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFnfADEWIJ5I",
        "outputId": "37e2439f-e31a-4a45-ff56-9a4e61563a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roi - homme + femme = reine_nom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analogies = [\n",
        "    ('auteur_nom', 'livre_nom', 'peintre_nom'),  # auteur est à livre ce que peintre est à ?\n",
        "    ('paris_nam', 'france_nam', 'londres_nam'),  # Paris est à France ce que Londres est à ?\n",
        "    ('passé_nom', 'présent_nom', 'avant_adv')     # passé est à présent ce que hier est à ?\n",
        "]"
      ],
      "metadata": {
        "id": "oiuJohylIVWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b, c in analogies:\n",
        "    try:\n",
        "        result = model.wv.most_similar(positive=[b, c], negative=[a], topn=1)\n",
        "        print(f\"{a} est à {b} ce que {c} est à {result[0][0]}\")\n",
        "    except KeyError:\n",
        "        print(f\"Un des mots dans l'analogie ({a}, {b}, {c}) n'est pas dans le vocabulaire.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m_IFnbeIkmV",
        "outputId": "5eac5f19-86d3-4fcb-ab5f-2dd55f7f04d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auteur_nom est à livre_nom ce que peintre_nom est à tableau_nom\n",
            "paris_nam est à france_nam ce que londres_nam est à angleterre_nam\n",
            "passé_nom est à présent_nom ce que avant_adv est à maintenant_adv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hugo_excerpt = \"\"\"\n",
        "c'était en effet un tableau digne d'intérêt que celui qui se déroulait\n",
        "en ce moment sous le porche ogival de notre dame. la petite esmeralda était\n",
        "assise sur le parvis, adossée contre un pilier. son bouc djali dormait à ses pieds.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ys5CeiH3Io_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_pos_mapping = {\n",
        "    \"C'\":\"c_pron\",\"en\":\"en_conj\",\"effet\":\"effet_nom\",\"un\":\"un_det\",\"tableau\": \"tableau_nom\",\"notre\":\"notre_adj\",\n",
        "    \"digne\":\"digne_adj\",\"d'\":\"d_prep\",\"intérêt\": \"intérêt_nom\", \"que\":\"que_conj\",\"celui\":\"celui_pron\",\n",
        "    \"qui\":\"qui_pron\",\"se\":\"se_pro\",\"en\":\"en_prep\",\"ce\":\"ce_det\",\"moment\": \"moment_nom\",\"sous\":\"sous_prep\",\n",
        "    \"le\":\"le_det\",\"porche\": \"porche_nom\",\"ogival\":\"ogival_adj\",\"la\":\"la_det\",\"petite\":\"petite_adj\", \"dame\": \"dame_nom\", \"esmeralda\": \"esmeralda_nam\",\n",
        "    \"était\":\"était_ver\",\"adossée\":\"adossée_ver\",\"contre\":\"contre_prep\",\"un\":\"un_det\",\"parvis\": \"parvis_nom\", \"pilier\": \"pilier_nom\", \"bouc\": \"bouc_nom\",\n",
        "    \"son\":\"son_adj\",\"à\":\"à_conj\",\"ses\":\"ses_adj\",\"bouc\":\"bouc_nom\",\"dormait\":\"dormait_ver\",\"djali\": \"djali_nam\", \"pieds\": \"pieds_nom\", \"fille\": \"fille_nom\",\n",
        "}"
      ],
      "metadata": {
        "id": "IBaUIQ2OLLju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = hugo_excerpt.lower().split()\n",
        "# Nettoyage très basique\n",
        "words = [word.strip(\".,;:!?()[]{}\\\"'\") for word in words]\n",
        "formatted_words = []\n",
        "for word in words:\n",
        "    if word in word_pos_mapping:\n",
        "        formatted_words.append(word_pos_mapping[word])\n",
        "    else:\n",
        "        formatted_words.append(word)  # Garder le mot original si pas de mapping\n",
        "\n",
        "# Filtrer les mots vides et ne garder que ceux présents dans le modèle\n",
        "filtered_words = [word for word in formatted_words if len(word) > 3 and word in model.wv]"
      ],
      "metadata": {
        "id": "0eqed0NuJC14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mots principaux de l'extrait avec leurs étiquettes grammaticales:\", filtered_words)\n",
        "\n",
        "# Trouver le \"centre sémantique\" de l'extrait\n",
        "if filtered_words:\n",
        "    excerpt_vector = np.mean([model.wv[word] for word in filtered_words], axis=0)\n",
        "    most_similar = model.wv.most_similar(positive=[excerpt_vector], topn=10)\n",
        "    print(\"\\nThèmes principaux détectés dans l'extrait:\")\n",
        "    for word, similarity in most_similar:\n",
        "        print(f\"  {word}: {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkAhIrBeJOEl",
        "outputId": "02fc4ef2-c4e9-4f6f-9a0e-3a5ff9af733b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mots principaux de l'extrait avec leurs étiquettes grammaticales: ['effet_nom', 'tableau_nom', 'digne_adj', 'moment_nom', 'porche_nom', 'ogival_adj', 'dame_nom', 'parvis_nom', 'pilier_nom', 'son_adj', 'bouc_nom', 'ses_adj', 'pieds_nom']\n",
            "\n",
            "Thèmes principaux détectés dans l'extrait:\n",
            "  porche_nom: 0.5719\n",
            "  ogival_adj: 0.5515\n",
            "  pilier_nom: 0.5458\n",
            "  parvis_nom: 0.5434\n",
            "  pilastre_nom: 0.4999\n",
            "  notre: 0.4823\n",
            "  fronton_nom: 0.4783\n",
            "  victoires_nam: 0.4777\n",
            "  église_nom: 0.4773\n",
            "  voûte_nom: 0.4766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testez avec vos propres fichiers txt"
      ],
      "metadata": {
        "id": "0yvw1F1iQp-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza"
      ],
      "metadata": {
        "id": "PkGISr9bQ02N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import stanza\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "bGSU_7j-QyKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stanza.download('fr')\n",
        "nlp = stanza.Pipeline('fr', processors='tokenize,pos,lemma')"
      ],
      "metadata": {
        "id": "jPsHK7WFQ8-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/content/\"\n",
        "\n",
        "define_batch_size = 1024  # Taille dynamique du batch\n",
        "\n",
        "def batch_process_texts(folder_path, batch_size=define_batch_size):\n",
        "    all_sentences = []\n",
        "    texts = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
        "                texts.append(file.read())\n",
        "\n",
        "    paragraphs = \"\\n\".join(texts).split(\"\\n\")\n",
        "    batches = [paragraphs[i:i + batch_size] for i in range(0, len(paragraphs), batch_size)]\n",
        "\n",
        "    for batch in batches:\n",
        "        batch_text = \"\\n\".join(batch)\n",
        "        doc = nlp(batch_text)\n",
        "        for sentence in doc.sentences:\n",
        "            lemmatized_sentence = [word.lemma for word in sentence.words if word.lemma is not None]\n",
        "            all_sentences.append(lemmatized_sentence)\n",
        "\n",
        "    return all_sentences\n",
        "\n",
        "sentences = batch_process_texts(folder_path, batch_size=define_batch_size)"
      ],
      "metadata": {
        "id": "i9cXkaeZLfBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(sentences, vector_size=300, window=20, min_count=2, sg=1)\n",
        "model.save(\"word2vec_model.model\")\n",
        "\n",
        "def word_similarity(word1, word2):\n",
        "    return model.wv.similarity(word1, word2)\n",
        "\n",
        "def word_analogy(word1, word2, word3):\n",
        "    return model.wv.most_similar(positive=[word2, word3], negative=[word1])\n",
        "\n",
        "\n",
        "def most_similar_words(word, topn=10):\n",
        "    try:\n",
        "        similar_words = model.wv.most_similar(word, topn=topn)\n",
        "        for w, sim in similar_words:\n",
        "            print(f\"{w}: {sim:.4f}\")\n",
        "    except KeyError:\n",
        "        print(f\"Le mot '{word}' n'est pas dans le vocabulaire du modèle.\")"
      ],
      "metadata": {
        "id": "fwWBZn7sRGSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"vectors.tsv\", \"w\", encoding=\"utf-8\") as vec_file, open(\"metadata.tsv\", \"w\", encoding=\"utf-8\") as meta_file:\n",
        "    for word in model.wv.index_to_key:\n",
        "        vector = model.wv[word]\n",
        "        vec_file.write(\"\\t\".join([str(x) for x in vector]) + \"\\n\")\n",
        "        meta_file.write(word + \"\\n\")"
      ],
      "metadata": {
        "id": "b9DQOePPRWqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous pouvez vous servir des derniers fichiers générés dans l'interface en ligne [tensorflow](https://projector.tensorflow.org/)"
      ],
      "metadata": {
        "id": "rYSyZpNvRXr8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D6tYi7aQRiSX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}