{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hxMNZZBdsT9AyRKnXcdOnis82XnHDehl",
      "authorship_tag": "ABX9TyMBZTQ1oUZGzp8dr/h/HEQg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e50c86d90b2b41dab62504b4479280a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02f8894b6f7948199982f4ed582a5dd6",
              "IPY_MODEL_84739b1c0f0040b38ea9f5466f45bd46",
              "IPY_MODEL_a0840100faa24d7e9990a3551ad1720f"
            ],
            "layout": "IPY_MODEL_f7f1457449a94544b6b69384eb1751e0"
          }
        },
        "02f8894b6f7948199982f4ed582a5dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e105b3b4c28d4832a46474a151c92f9f",
            "placeholder": "​",
            "style": "IPY_MODEL_566f95f638bc4fa7a5866d72973831ea",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: "
          }
        },
        "84739b1c0f0040b38ea9f5466f45bd46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edca62ce6bdf47e4abe2ae9e9586f418",
            "max": 52448,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9bf5a763b2264f068e5c230d9a991312",
            "value": 52448
          }
        },
        "a0840100faa24d7e9990a3551ad1720f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d150af0a349d4716bc99ac06a7369cf7",
            "placeholder": "​",
            "style": "IPY_MODEL_dc446c2bb0114e83beb4b69436682698",
            "value": " 424k/? [00:00&lt;00:00, 17.5MB/s]"
          }
        },
        "f7f1457449a94544b6b69384eb1751e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e105b3b4c28d4832a46474a151c92f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "566f95f638bc4fa7a5866d72973831ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edca62ce6bdf47e4abe2ae9e9586f418": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bf5a763b2264f068e5c230d9a991312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d150af0a349d4716bc99ac06a7369cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc446c2bb0114e83beb4b69436682698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OdysseusPolymetis/colabs_for_nlp/blob/main/2_analyse_textuelle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ANALYSE TEXTUELLE, LES BASES**"
      ],
      "metadata": {
        "id": "_Z74vm47glyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza"
      ],
      "metadata": {
        "id": "SREcs0t-OqAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Qu'est-ce que c'est que l'analyse textuelle (automatique), rapidement\n",
        "En fait ça peut toucher beaucoup de domaines. Ici, on va en voir plusieurs, entre autres la **tokenisation**, la **lemmatisation**, le **postagging**. J'appellerai ça les étapes de \"pre-processing\", de travail préliminaire.\n",
        "<br>En effet, on a très souvent besoin, pour faire des choses plus poussées, de ces étapes pour éviter de créer des biais dans les analyses qui vont suivre.\n",
        "<br>Voici quelques exemples de biais possibles, si l'on ne passe pas par certaines de ces étapes de pré-traitement."
      ],
      "metadata": {
        "id": "Rt0eU-qsLb10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prenons l'exemple des nuages de mots. C'est globalement facile à faire, et ça permet souvent (de manière parfois un peu artificielle) d'illustrer son propos.\n",
        "Ici voyons ce qu'on obtient si on fait un nuage de mots sur les _Trois Mousquetaires_."
      ],
      "metadata": {
        "id": "No917ErdNBKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1g8RLOXodDDGBgfR6tJ-jvVG1JHTdz65f)"
      ],
      "metadata": {
        "id": "len26rjUQB8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce nuage est fait avec des données brutes. C'est-à-dire qu'on a juste injecté les mots du texte, tels quels. Globalement, on ne peut pas en faire grand chose et ce n'est pas représentatif. Pourquoi ? Déjà parce que chaque mot est encore fléchi, et donc pour chaque \"fut\", \"est\", \"sera\", chaque mot est compté comme un mot à part, et non comme une forme de \"être\".\n",
        "<br>Une première solution est donc de **lemmatiser**."
      ],
      "metadata": {
        "id": "o6ICTfTEQGoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=10vv3sdsqLMBMXYW5-YAKp9ztgYq_sJDs)"
      ],
      "metadata": {
        "id": "i-lzw58DQt_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "C'est déjà mieux, mais ça n'est pas fou non plus. Il y a encore de nombreux mots dont on se fiche complètement. Exemple, \"faire\", \"plus\", etc.\n",
        "<br>On a donc encore une étape, celle d'enlever les **mots-outils**, ou \"stopwords\", et la ponctuation. Les mots-outils sont les mots qui n'ont qu'un faible poids sémantique (qui peuvent avoir leur importance pour une étude dédiée, certes), mais qui font du bruit lors d'une analyse statistique de base.\n",
        "<br>Enlevons-les."
      ],
      "metadata": {
        "id": "wAHGkN0VUCJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1c9PxvrkXDTNZTC7QOGNCi2qOQ5_fI9th)"
      ],
      "metadata": {
        "id": "vX_4iyBqWg4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comment on pré-traite ?\n",
        "Il y a plusieurs écoles, et donc aussi plusieurs modules pour le faire.\n",
        "<br>D'expérience personnelle, il y a les modules rapides et qui donnent des résultats plus mitigés, et des modules plus longs qui sont généralement meilleurs (mais pas forcément).\n",
        "<br>Ici, je vais vous montrer trois modules avec des qualités et des défauts, pour le français (mais ils ont aussi des modèles en d'autres langues)."
      ],
      "metadata": {
        "id": "zLIKh_80WtdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<center>**LE TAL : TOKENISATION, LEMMATISATION, POSTAGGING**</center>"
      ],
      "metadata": {
        "id": "mj7F-HDpcCkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons tester un outil qui permet de faire ces trois opérations, **`stanza`**. Il en existe beaucoup d'autres."
      ],
      "metadata": {
        "id": "uQIzGqJzcUVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preface=\"Tant qu’il existera, par le fait des lois et des mœurs, une damnation sociale créant artificiellement, en pleine civilisation, des enfers, et compliquant d’une fatalité humaine la destinée qui est divine ; tant que les trois problèmes du siècle, la dégradation de l’homme par le prolétariat, la déchéance de la femme par la faim, l’atrophie de l’enfant par la nuit, ne seront pas résolus ; tant que, dans de certaines régions, l’asphyxie sociale sera possible ; en d’autres termes, et à un point de vue plus étendu encore, tant qu’il y aura sur la terre ignorance et misère, des livres de la nature de celui-ci pourront ne pas être inutiles.\""
      ],
      "metadata": {
        "id": "VR5RRUfQc5u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1GEgd5cQoJkTm5PRWfixxOKHe3uOlxFqo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPKLpCvueSdj",
        "outputId": "6cb340d8-82ea-4d33-9011-e6992ca1e36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GEgd5cQoJkTm5PRWfixxOKHe3uOlxFqo\n",
            "To: /content/miserables.txt\n",
            "100% 3.17M/3.17M [00:00<00:00, 11.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath_of_text = \"/content/miserables.txt\""
      ],
      "metadata": {
        "id": "7EmoQaQkf0xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_text = open(filepath_of_text, encoding=\"utf-8\").read()"
      ],
      "metadata": {
        "id": "XR4sW3GHgpVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**stanza (ancien Stanford CoreNLP)**"
      ],
      "metadata": {
        "id": "7r_DV1BTw4Cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Personnellement, c'est l'analyseur que j'utilise quand je n'ai pas besoin de faire de représentations graphiques de mes résultats. Il est rapide et efficace."
      ],
      "metadata": {
        "id": "XCtmOg83d83p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Je mentionne `stanza` en particulier pour trois raisons :\n",
        "<br>- d'abord parce qu'il dispose d'un très grand nombre de modèles de langue, et pas forcément des langues très répandues,\n",
        "<br>- ensuite parce qu'il est très rapide, et niveau performance tout à fait satisfaisant pour les gros corpus,\n",
        "<br>- enfin parce que je le trouve facile à manipuler et à implémenter."
      ],
      "metadata": {
        "id": "jN7vhzYuWTO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mais il faut garder en tête qu'il en existe bien d'autres qui fonctionnent vraiment très bien, avec un nombre de modèles qui se multiplie. Je pense au tagger de BERT,  ou de `flair` entre autres. Mais ça nécessite d'être un peu plus aguerri."
      ],
      "metadata": {
        "id": "mREr1vy_WzEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Là encore, il existe plusieurs modèles rien que pour le français (je vous mets ici la [liste des modèles](https://stanfordnlp.github.io/stanza/performance.html) dans d'autres langues), mais le modèle par défaut peut être appelé avec `fr`.\n",
        "<br>C'est un modèle sur du français moderne, donc ne fonctionne pas avec l'ancien français etc. (mais un modèle existe aussi pour l'ancien français, appelé par défaut avec `fro`)."
      ],
      "metadata": {
        "id": "hPEkXPIxeUob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "stanza.download('fr')"
      ],
      "metadata": {
        "id": "sJXi9pljw2DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On commence par lui spécifier une Pipeline, c'est-à-dire qu'on lui signifie quels processeurs il va devoir mobiliser pour les opérations suivantes et en quelle langue. L'avantage de cette opération est qu'on ne mobilise pas l'artillerie lourde quand on veut faire des opérations simples)."
      ],
      "metadata": {
        "id": "BKCT-NaPxpbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_stanza = stanza.Pipeline(lang='fr', processors='tokenize,mwt,pos,lemma')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429,
          "referenced_widgets": [
            "e50c86d90b2b41dab62504b4479280a1",
            "02f8894b6f7948199982f4ed582a5dd6",
            "84739b1c0f0040b38ea9f5466f45bd46",
            "a0840100faa24d7e9990a3551ad1720f",
            "f7f1457449a94544b6b69384eb1751e0",
            "e105b3b4c28d4832a46474a151c92f9f",
            "566f95f638bc4fa7a5866d72973831ea",
            "edca62ce6bdf47e4abe2ae9e9586f418",
            "9bf5a763b2264f068e5c230d9a991312",
            "d150af0a349d4716bc99ac06a7369cf7",
            "dc446c2bb0114e83beb4b69436682698"
          ]
        },
        "id": "9x5kKE7rxTgB",
        "outputId": "60adf7a4-a28b-424c-bb11-a8d6fe0ef4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e50c86d90b2b41dab62504b4479280a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "INFO:stanza:Loading these models for language: fr (French):\n",
            "=================================\n",
            "| Processor | Package           |\n",
            "---------------------------------\n",
            "| tokenize  | combined          |\n",
            "| mwt       | combined          |\n",
            "| pos       | combined_charlm   |\n",
            "| lemma     | combined_nocharlm |\n",
            "=================================\n",
            "\n",
            "INFO:stanza:Using device: cuda\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: mwt\n",
            "INFO:stanza:Loading: pos\n",
            "INFO:stanza:Loading: lemma\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant, nous pouvons lancer le TAL sur la préface."
      ],
      "metadata": {
        "id": "BUd62DkjgcvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "miserables_stanza=nlp_stanza(preface)"
      ],
      "metadata": {
        "id": "TMPY243ZyE8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voyons maintenant ses résultats."
      ],
      "metadata": {
        "id": "oSS-MkX_gr7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in miserables_stanza.sentences:\n",
        "  for token in sent.words:\n",
        "    print(token.text + ' - ' + token.lemma + ' - ' + token.pos)"
      ],
      "metadata": {
        "id": "jNXzUVFZzojD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Globalement ça marche d'enfer."
      ],
      "metadata": {
        "id": "rmiFFvVB2SCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<center>**LES ENTITES NOMMEES**</center>"
      ],
      "metadata": {
        "id": "fd2MBMVca7gt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les **entités nommées** sont des éléments textuels connus et catégorisables. Par exemple, un NER (Named Entity Recognition) qui fonctionnerait bien comprendrait \"la ville aux sept collines\" comme un nom de lieu, et comme Rome."
      ],
      "metadata": {
        "id": "V7AgI0SZg_SH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**stanza**"
      ],
      "metadata": {
        "id": "W3GyVb8NboAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`stanza`** aussi peut permettre de façon beaucoup plus rapide d'obtenir les NER. Ne serait-ce que parce que, par défaut, il demande de définir une Pipeline (un processus qui permet de ne pas faire toutes les opérations en même temps)."
      ],
      "metadata": {
        "id": "alSLjgnbbsW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stanza_ner = stanza.Pipeline(lang='fr', processors='tokenize,ner')"
      ],
      "metadata": {
        "id": "aEcFlfwo1T5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = stanza_ner(\"qui avaient couru sur son compte au moment où il était arrivé dans le diocèse. Vrai ou faux, ce qu'on dit des hommes tient souvent autant de place dans leur vie et surtout dans leur destinée que ce qu'ils font. M. Myriel était fils d'un conseiller au parlement d'Aix ; noblesse de robe.\")"
      ],
      "metadata": {
        "id": "om7BELiY2h_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for ent in doc.ents], sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2punkmf625AI",
        "outputId": "e856920e-5fa3-495f-fc06-3a7d0009ec03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entity: M. Myriel\ttype: PER\n",
            "entity: Aix\ttype: LOC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les résultats sont bons pour ce passage, semble-t-il."
      ],
      "metadata": {
        "id": "ZqaotLQ33KwJ"
      }
    }
  ]
}